{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27ef7793",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T03:40:18.432492Z",
     "iopub.status.busy": "2022-05-24T03:40:18.432120Z",
     "iopub.status.idle": "2022-05-24T03:40:19.185182Z",
     "shell.execute_reply": "2022-05-24T03:40:19.184226Z"
    },
    "papermill": {
     "duration": 0.780077,
     "end_time": "2022-05-24T03:40:19.187527",
     "exception": false,
     "start_time": "2022-05-24T03:40:18.407450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p ./code/config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a763bb7",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-05-24T03:40:19.255472Z",
     "iopub.status.busy": "2022-05-24T03:40:19.255211Z",
     "iopub.status.idle": "2022-05-24T03:40:19.262470Z",
     "shell.execute_reply": "2022-05-24T03:40:19.261831Z"
    },
    "papermill": {
     "duration": 0.04217,
     "end_time": "2022-05-24T03:40:19.264553",
     "exception": false,
     "start_time": "2022-05-24T03:40:19.222383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./code/test_data_prep.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./code/test_data_prep.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from joblib import delayed,Parallel\n",
    "import json, random\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf, re, math\n",
    "from tqdm import tqdm\n",
    "\n",
    "SR = 44100\n",
    "SEC = 5\n",
    "atleast_sec = 1#3\n",
    "n_fft = 1024\n",
    "hop_length = 512\n",
    "n_mels = 128\n",
    "NewMax = 255.\n",
    "NewMin = 0.\n",
    "\n",
    "\n",
    "\n",
    "folder_wav = f'./test_5sec_mel_spec'\n",
    "\n",
    "if not os.path.exists(folder_wav):\n",
    "    os.makedirs(folder_wav)\n",
    "\n",
    "\n",
    "def image_creation(file,):\n",
    "    \n",
    "    y, sr = librosa.load(f'../input/birdclef-2022/test_soundscapes/{file}', sr = None)\n",
    "    resample_y = librosa.resample(y, orig_sr=sr, target_sr=SR)\n",
    "    for i in range(0, int(len(resample_y)/44100), SEC):\n",
    "        \n",
    "        ## lets check if the sound track is atleast greater than 3 sec\n",
    "        wave = resample_y[i*SR:(i+SEC)*SR]\n",
    "        \n",
    "        if len(wave)> atleast_sec * SR:\n",
    "            \n",
    "            if len(wave)< SEC * SR:\n",
    "                wave = np.concatenate([wave, np.array([0.]*abs(wave.shape[0] - SEC*SR))])  \n",
    "\n",
    "            S = librosa.feature.melspectrogram(wave, sr=SR, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels,win_length=None)\n",
    "            S_DB = librosa.power_to_db(S, ref=np.max)\n",
    "            S_DB = (((S_DB - S_DB.min()) * (NewMax - NewMin)) / (S_DB.max() - S_DB.min())) + NewMin\n",
    "            S_DB = np.flipud(S_DB)\n",
    "            image = np.dstack([S_DB,S_DB,S_DB])\n",
    "            image = image.astype(np.uint8)\n",
    "            filename = file.split('.')[0]\n",
    "            filename = f'{filename}'+f'_sec_{i+SEC}'\n",
    "            #image = cv2.resize(image,[IMAGE_SHAPE, IMAGE_SHAPE])\n",
    "            cv2.imwrite(f'{folder_wav}/{filename}.jpg',image)\n",
    "            \n",
    "test_sound = os.listdir('../input/birdclef-2022/test_soundscapes')\n",
    "\n",
    "_ = Parallel(n_jobs=2, verbose=1)(\n",
    "    delayed(image_creation)(\n",
    "    file,\n",
    "    ) for file in test_sound#[:5]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d981111c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T03:40:19.307508Z",
     "iopub.status.busy": "2022-05-24T03:40:19.306949Z",
     "iopub.status.idle": "2022-05-24T03:40:34.259848Z",
     "shell.execute_reply": "2022-05-24T03:40:34.259033Z"
    },
    "papermill": {
     "duration": 14.976382,
     "end_time": "2022-05-24T03:40:34.262036",
     "exception": false,
     "start_time": "2022-05-24T03:40:19.285654",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\r\n",
      "code/test_data_prep.py:55: FutureWarning: Pass y=[0.1274449  0.13749163 0.10165688 ... 0.10868431 0.11853973 0.11962135] as keyword args. From version 0.10 passing these as positional arguments will result in an error\r\n",
      "  S = librosa.feature.melspectrogram(wave, sr=SR, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels,win_length=None)\r\n",
      "code/test_data_prep.py:55: FutureWarning: Pass y=[ 0.11413617  0.11052517  0.11118273 ... -0.05302466 -0.04651844\r\n",
      " -0.0386673 ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\r\n",
      "  S = librosa.feature.melspectrogram(wave, sr=SR, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels,win_length=None)\r\n",
      "code/test_data_prep.py:55: FutureWarning: Pass y=[-0.03370828 -0.03307219 -0.03623257 ...  0.12704208  0.1257558\r\n",
      "  0.12209577] as keyword args. From version 0.10 passing these as positional arguments will result in an error\r\n",
      "  S = librosa.feature.melspectrogram(wave, sr=SR, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels,win_length=None)\r\n",
      "code/test_data_prep.py:55: FutureWarning: Pass y=[ 0.12492188  0.13052376  0.12851499 ... -0.0184685  -0.02043677\r\n",
      " -0.01920972] as keyword args. From version 0.10 passing these as positional arguments will result in an error\r\n",
      "  S = librosa.feature.melspectrogram(wave, sr=SR, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels,win_length=None)\r\n",
      "code/test_data_prep.py:55: FutureWarning: Pass y=[-0.01722866 -0.01165571 -0.00425289 ...  0.07561097  0.07991067\r\n",
      "  0.08281371] as keyword args. From version 0.10 passing these as positional arguments will result in an error\r\n",
      "  S = librosa.feature.melspectrogram(wave, sr=SR, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels,win_length=None)\r\n",
      "code/test_data_prep.py:55: FutureWarning: Pass y=[0.06413147 0.0412131  0.04987637 ... 0.08097219 0.08211756 0.08364192] as keyword args. From version 0.10 passing these as positional arguments will result in an error\r\n",
      "  S = librosa.feature.melspectrogram(wave, sr=SR, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels,win_length=None)\r\n",
      "code/test_data_prep.py:55: FutureWarning: Pass y=[0.08250432 0.08245447 0.08663426 ... 0.06615249 0.06038672 0.05432658] as keyword args. From version 0.10 passing these as positional arguments will result in an error\r\n",
      "  S = librosa.feature.melspectrogram(wave, sr=SR, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels,win_length=None)\r\n",
      "code/test_data_prep.py:55: FutureWarning: Pass y=[ 5.3354759e-02  5.9318967e-02  6.7925468e-02 ... -6.1520129e-03\r\n",
      "  8.6096341e-05 -1.4448937e-03] as keyword args. From version 0.10 passing these as positional arguments will result in an error\r\n",
      "  S = librosa.feature.melspectrogram(wave, sr=SR, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels,win_length=None)\r\n",
      "code/test_data_prep.py:55: FutureWarning: Pass y=[-0.00812749 -0.01253498 -0.0119512  ...  0.1096983   0.10964434\r\n",
      "  0.11093707] as keyword args. From version 0.10 passing these as positional arguments will result in an error\r\n",
      "  S = librosa.feature.melspectrogram(wave, sr=SR, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels,win_length=None)\r\n",
      "code/test_data_prep.py:55: FutureWarning: Pass y=[0.10447396 0.10050296 0.10718436 ... 0.10900335 0.11234519 0.11983627] as keyword args. From version 0.10 passing these as positional arguments will result in an error\r\n",
      "  S = librosa.feature.melspectrogram(wave, sr=SR, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels,win_length=None)\r\n",
      "code/test_data_prep.py:55: FutureWarning: Pass y=[0.11851542 0.10903966 0.1017567  ... 0.13159142 0.13512357 0.13728885] as keyword args. From version 0.10 passing these as positional arguments will result in an error\r\n",
      "  S = librosa.feature.melspectrogram(wave, sr=SR, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels,win_length=None)\r\n",
      "code/test_data_prep.py:55: FutureWarning: Pass y=[0.13665636 0.13993496 0.1442591  ... 0.0194697  0.03554935 0.02555438] as keyword args. From version 0.10 passing these as positional arguments will result in an error\r\n",
      "  S = librosa.feature.melspectrogram(wave, sr=SR, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels,win_length=None)\r\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    4.9s finished\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python code/test_data_prep.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2eeaffa3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T03:40:34.309882Z",
     "iopub.status.busy": "2022-05-24T03:40:34.309628Z",
     "iopub.status.idle": "2022-05-24T03:40:34.315319Z",
     "shell.execute_reply": "2022-05-24T03:40:34.314624Z"
    },
    "papermill": {
     "duration": 0.032731,
     "end_time": "2022-05-24T03:40:34.317196",
     "exception": false,
     "start_time": "2022-05-24T03:40:34.284465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./code/config/config.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./code/config/config.py\n",
    "\n",
    "class config:\n",
    "    EPOCHS = 20  # 20\n",
    "    BATCH_SIZE = 32\n",
    "    WAVE_LENGTH = 441000\n",
    "    IMAGE_SIZE = -1\n",
    "    IMG_FREQ = 128\n",
    "    IMG_TIME = 862\n",
    "    FOLD = 7#validation fold\n",
    "    WEIGHT_SAVE = \"binary_v3_SED\"\n",
    "    N_CLASSES = 2\n",
    "    IS_COLAB  = True\n",
    "    DATA_LINK = \"gs://kds-facb268a69ae0d4d20601c59a3b4f9215456ebf5a0246b7519d38de0\"\n",
    "    DATA_PATH = \"data/tfrec/v3/\"\n",
    "    SEED = 1\n",
    "    model_type = \"resnet50\"\n",
    "    WORKERS = 6\n",
    "    sample_rate = 44100\n",
    "    n_fft = 1024\n",
    "    win_length = None\n",
    "    hop_length = 512\n",
    "    n_mels = 128\n",
    "    LR_START = 0.000001  # 0.000001\n",
    "    LR_MAX = 0.000005  # 0.00001\n",
    "    LR_MIN = 0.0000001  # 0.000001\n",
    "    LR_RAMP = 4\n",
    "    SAVE_DIR = \"../input/bird-clief-binary-v3-sed\"\n",
    "    \n",
    "\n",
    "    RESUME = False\n",
    "    RESUME_EPOCH = 0\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.229, 0.224, 0.225]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa8f61ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T03:40:34.363332Z",
     "iopub.status.busy": "2022-05-24T03:40:34.363003Z",
     "iopub.status.idle": "2022-05-24T03:40:34.370480Z",
     "shell.execute_reply": "2022-05-24T03:40:34.369630Z"
    },
    "papermill": {
     "duration": 0.033066,
     "end_time": "2022-05-24T03:40:34.372624",
     "exception": false,
     "start_time": "2022-05-24T03:40:34.339558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./code/utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./code/utils.py\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from config.config import config\n",
    "\n",
    "\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "\n",
    "def decode_image(image_data):\n",
    "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
    "    #image = tf.image.resize(image, [config.IMAGE_SIZE//2, config.IMAGE_SIZE])\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    # normalization\n",
    "    image = image - config.mean  # [0.485, 0.456, 0.406]\n",
    "    image = image / config.std  # [0.229, 0.224, 0.225]\n",
    "    return image\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_label(file_path):\n",
    "    # Convert the path to a list of path components\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    # The second to last is the class-directory\n",
    "    #one_hot = parts[-2] == class_names\n",
    "    # Integer encode the label\n",
    "    return tf.strings.split(parts[-1], '.')[0]\n",
    "\n",
    "def decode_img(img):\n",
    "    # Convert the compressed string to a 3D uint8 tensor\n",
    "    image = tf.io.decode_jpeg(img, channels=3)\n",
    "    # Resize the image to the desired size\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    # normalization\n",
    "    image = image - config.mean  # [0.485, 0.456, 0.406]\n",
    "    image = image / config.std  # [0.229, 0.224, 0.225]\n",
    "    return image\n",
    "\n",
    "def process_path(file_path):\n",
    "    label = get_label(file_path)\n",
    "    # Load the raw data from the file as a string\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "    return img, label\n",
    "\n",
    "def get_eval_dataset():\n",
    "    list_ds = tf.data.Dataset.list_files(str('./test_5sec_mel_spec/*'), shuffle=False)\n",
    "    dataset = list_ds.map(process_path)\n",
    "    dataset = dataset.repeat()  # the training dataset must repeat for several epochs\n",
    "    #dataset = dataset.shuffle(2048)\n",
    "    dataset = dataset.batch(config.BATCH_SIZE, num_parallel_calls=AUTO, drop_remainder=False)\n",
    "    dataset = dataset.prefetch(\n",
    "        AUTO\n",
    "    )  # prefetch next batch while training (autotune prefetch buffer size)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a5d9863",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T03:40:34.419825Z",
     "iopub.status.busy": "2022-05-24T03:40:34.419618Z",
     "iopub.status.idle": "2022-05-24T03:40:34.430058Z",
     "shell.execute_reply": "2022-05-24T03:40:34.429296Z"
    },
    "papermill": {
     "duration": 0.036431,
     "end_time": "2022-05-24T03:40:34.432233",
     "exception": false,
     "start_time": "2022-05-24T03:40:34.395802",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing code/train_soundscape_binary_prediction.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/train_soundscape_binary_prediction.py\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "from datetime import datetime\n",
    "from config.config import config\n",
    "from utils import *\n",
    "import shutil\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n",
    "    # set: this is always the case on Kaggle.\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print(\"Running on TPU \", tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.TPUStrategy(tpu)\n",
    "else:\n",
    "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)\n",
    "config.BATCH_SIZE = config.BATCH_SIZE * strategy.num_replicas_in_sync\n",
    "\n",
    "test_prediction = []\n",
    "test_targets = []\n",
    "test_file = []\n",
    "\n",
    "## get the model for 8 fold\n",
    "\n",
    "def model_get(model, file):\n",
    "    model_list = []\n",
    "    for fold in range(0,8):#8\n",
    "        model_list.append(tf.keras.models.load_model(model))\n",
    "        _=model_list[fold].load_weights(\n",
    "        file + f'/fold_{fold}/'+ \"weights/\" + \"best.hdf5\",\n",
    "    )  ## work on the path\n",
    "    return model_list\n",
    "\n",
    "#for fold in range(0,10):\n",
    "## model load\n",
    "K.clear_session()\n",
    "model_list1 = model_get(\"../input/birdclif-saved-model/binary_v3_SED\", \"../input/bird-clief-binary-v3-sed\")\n",
    "model_list2 = model_get(\"../input/birdclif-saved-model/binary_v4_SED\", \"../input/bird-clief-binary-v4-sed\")\n",
    "model_list = model_list1 + model_list2\n",
    "\n",
    "test_dataset = get_eval_dataset()\n",
    "actual_count = len(os.listdir('./test_5sec_mel_spec'))\n",
    "\n",
    "\n",
    "test_prediction_fold = []\n",
    "test_targets_fold = []\n",
    "test_file_fold = []\n",
    "#for rr, m in enumerate(model_list):\n",
    "count = 0\n",
    "#print('model ',rr)\n",
    "test_prediction_sub_model_0_0 = []\n",
    "test_prediction_sub_model_0_1 = []\n",
    "test_prediction_sub_model_0_2 = []\n",
    "test_prediction_sub_model_0_3 = []\n",
    "test_prediction_sub_model_0_4 = []\n",
    "test_prediction_sub_model_0_5 = []\n",
    "test_prediction_sub_model_0_6 = []\n",
    "test_prediction_sub_model_0_7 = []\n",
    "\n",
    "test_prediction_sub_model_1_0 = []\n",
    "test_prediction_sub_model_1_1 = []\n",
    "test_prediction_sub_model_1_2 = []\n",
    "test_prediction_sub_model_1_3 = []\n",
    "test_prediction_sub_model_1_4 = []\n",
    "test_prediction_sub_model_1_5 = []\n",
    "test_prediction_sub_model_1_6 = []\n",
    "test_prediction_sub_model_1_7 = []\n",
    "test_targets_sub = []\n",
    "test_file_sub = []\n",
    "for element in test_dataset:\n",
    "\n",
    "    test_prediction_sub_model_0_0.append(tf.nn.softmax(model_list[0].__call__(element[0]))[:,1])\n",
    "    test_prediction_sub_model_0_1.append(tf.nn.softmax(model_list[1].__call__(element[0]))[:,1])\n",
    "    test_prediction_sub_model_0_2.append(tf.nn.softmax(model_list[2].__call__(element[0]))[:,1])\n",
    "    test_prediction_sub_model_0_3.append(tf.nn.softmax(model_list[3].__call__(element[0]))[:,1])\n",
    "    test_prediction_sub_model_0_4.append(tf.nn.softmax(model_list[4].__call__(element[0]))[:,1])\n",
    "    test_prediction_sub_model_0_5.append(tf.nn.softmax(model_list[5].__call__(element[0]))[:,1])\n",
    "    test_prediction_sub_model_0_6.append(tf.nn.softmax(model_list[6].__call__(element[0]))[:,1])\n",
    "    test_prediction_sub_model_0_7.append(tf.nn.softmax(model_list[7].__call__(element[0]))[:,1])\n",
    "    \n",
    "    \n",
    "    test_prediction_sub_model_1_0.append(tf.nn.softmax(model_list[8].__call__(element[0]))[:,1])\n",
    "    test_prediction_sub_model_1_1.append(tf.nn.softmax(model_list[9].__call__(element[0]))[:,1])\n",
    "    test_prediction_sub_model_1_2.append(tf.nn.softmax(model_list[10].__call__(element[0]))[:,1])\n",
    "    test_prediction_sub_model_1_3.append(tf.nn.softmax(model_list[11].__call__(element[0]))[:,1])\n",
    "    test_prediction_sub_model_1_4.append(tf.nn.softmax(model_list[12].__call__(element[0]))[:,1])\n",
    "    test_prediction_sub_model_1_5.append(tf.nn.softmax(model_list[13].__call__(element[0]))[:,1])\n",
    "    test_prediction_sub_model_1_6.append(tf.nn.softmax(model_list[14].__call__(element[0]))[:,1])\n",
    "    test_prediction_sub_model_1_7.append(tf.nn.softmax(model_list[15].__call__(element[0]))[:,1])\n",
    "    #test_targets_sub.append(np.argmax(element[1].numpy(),axis=1))\n",
    "    test_file_sub.append(element[1].numpy())\n",
    "\n",
    "    if count * config.BATCH_SIZE > actual_count + 20:  # this 20 is for safty\n",
    "        print('the break ',count * config.BATCH_SIZE)\n",
    "        break\n",
    "    print('the out ',count * config.BATCH_SIZE)\n",
    "    count += 1\n",
    "\n",
    "test_prediction_fold.append(np.concatenate(test_prediction_sub_model_0_0)[:actual_count])\n",
    "test_prediction_fold.append(np.concatenate(test_prediction_sub_model_0_1)[:actual_count])\n",
    "test_prediction_fold.append(np.concatenate(test_prediction_sub_model_0_2)[:actual_count])\n",
    "test_prediction_fold.append(np.concatenate(test_prediction_sub_model_0_3)[:actual_count])\n",
    "test_prediction_fold.append(np.concatenate(test_prediction_sub_model_0_4)[:actual_count])\n",
    "test_prediction_fold.append(np.concatenate(test_prediction_sub_model_0_5)[:actual_count])\n",
    "test_prediction_fold.append(np.concatenate(test_prediction_sub_model_0_6)[:actual_count])\n",
    "test_prediction_fold.append(np.concatenate(test_prediction_sub_model_0_7)[:actual_count])\n",
    "\n",
    "test_prediction_fold.append(np.concatenate(test_prediction_sub_model_1_0)[:actual_count])\n",
    "test_prediction_fold.append(np.concatenate(test_prediction_sub_model_1_1)[:actual_count])\n",
    "test_prediction_fold.append(np.concatenate(test_prediction_sub_model_1_2)[:actual_count])\n",
    "test_prediction_fold.append(np.concatenate(test_prediction_sub_model_1_3)[:actual_count])\n",
    "test_prediction_fold.append(np.concatenate(test_prediction_sub_model_1_4)[:actual_count])\n",
    "test_prediction_fold.append(np.concatenate(test_prediction_sub_model_1_5)[:actual_count])\n",
    "test_prediction_fold.append(np.concatenate(test_prediction_sub_model_1_6)[:actual_count])\n",
    "test_prediction_fold.append(np.concatenate(test_prediction_sub_model_1_7)[:actual_count])\n",
    "#test_targets_fold.append(np.concatenate(test_targets_sub)[:actual_count])\n",
    "test_file_fold.append(np.concatenate(test_file_sub)[:actual_count])\n",
    "\n",
    "test_prediction = np.array(test_prediction_fold).squeeze().mean(axis=0)\n",
    "#test_targets = test_targets_fold[0]\n",
    "test_file = test_file_fold[0]\n",
    "\n",
    "\n",
    "oof_dict = {\n",
    "\n",
    "    'itemid':test_file,\n",
    "    #'hasbird':test_targets,\n",
    "    'prediction':test_prediction,\n",
    "}\n",
    "\n",
    "oof_df = pd.DataFrame.from_dict(oof_dict)\n",
    "oof_df['itemid'] =  oof_df['itemid'].map(lambda x: x.decode(\"utf-8\")) \n",
    "oof_df.to_csv(f\"binary_prediction.csv\", index = False)\n",
    "\n",
    "## 5 sec\n",
    "## happywhale-tfrev-train-sound-v2\n",
    "## gs://kds-22c2720af882134066efd729205635efc3a6ce12dfa19de78bd41475\n",
    "\n",
    "## 10 sec\n",
    "## happywhale-tfrev-train-sound-v1\n",
    "## gs://kds-168dba29a1eb377402725ff4ec9b4a8afa032dfacaa1f1b84639cc59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6f97a5",
   "metadata": {
    "papermill": {
     "duration": 0.022734,
     "end_time": "2022-05-24T03:40:34.478446",
     "exception": false,
     "start_time": "2022-05-24T03:40:34.455712",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12978d99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T03:40:34.529283Z",
     "iopub.status.busy": "2022-05-24T03:40:34.528671Z",
     "iopub.status.idle": "2022-05-24T03:44:15.105872Z",
     "shell.execute_reply": "2022-05-24T03:44:15.105053Z"
    },
    "papermill": {
     "duration": 220.606036,
     "end_time": "2022-05-24T03:44:15.107909",
     "exception": false,
     "start_time": "2022-05-24T03:40:34.501873",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-24 03:40:38.768507: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n",
      "2022-05-24 03:40:38.907868: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n",
      "2022-05-24 03:40:38.908727: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n",
      "2022-05-24 03:40:38.910581: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\r\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n",
      "2022-05-24 03:40:38.910923: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n",
      "2022-05-24 03:40:38.911710: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n",
      "2022-05-24 03:40:38.912451: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n",
      "2022-05-24 03:40:41.067561: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n",
      "2022-05-24 03:40:41.068513: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n",
      "2022-05-24 03:40:41.069256: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n",
      "2022-05-24 03:40:41.070589: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\r\n",
      "1 Physical GPUs, 1 Logical GPU\r\n",
      "REPLICAS:  1\r\n",
      "/opt/conda/lib/python3.7/site-packages/keras/layers/core.py:1045: UserWarning: model is not loaded, but a Lambda layer uses it. It may cause errors.\r\n",
      "  , UserWarning)\r\n",
      "2022-05-24 03:43:34.976389: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\r\n",
      "2022-05-24 03:43:36.610317: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\r\n",
      "the out  0\r\n",
      "the out  32\r\n",
      "the break  64\r\n"
     ]
    }
   ],
   "source": [
    "!python code/train_soundscape_binary_prediction.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233d57bd",
   "metadata": {
    "papermill": {
     "duration": 0.025917,
     "end_time": "2022-05-24T03:44:15.160204",
     "exception": false,
     "start_time": "2022-05-24T03:44:15.134287",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## now the bird prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bfee960",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T03:44:15.213923Z",
     "iopub.status.busy": "2022-05-24T03:44:15.213675Z",
     "iopub.status.idle": "2022-05-24T03:44:15.219384Z",
     "shell.execute_reply": "2022-05-24T03:44:15.218730Z"
    },
    "papermill": {
     "duration": 0.034552,
     "end_time": "2022-05-24T03:44:15.221378",
     "exception": false,
     "start_time": "2022-05-24T03:44:15.186826",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./code/config/config.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./code/config/config.py\n",
    "\n",
    "\n",
    "class config:\n",
    "    EPOCHS = 20  # 20\n",
    "    BATCH_SIZE = 16#32\n",
    "    WAVE_LENGTH = 441000\n",
    "    IMAGE_SIZE = -1\n",
    "    IMG_FREQ = 128\n",
    "    IMG_TIME = 862\n",
    "    FOLD = 8#validation fold\n",
    "    WEIGHT_SAVE = \"comp_v4_SED\"\n",
    "    N_CLASSES = 152\n",
    "    IS_COLAB  = True\n",
    "    DATA_LINK = \"gs://kds-a8fad3a0c9fb1420c6172cc9145a3232c612596be1f376e595a4c4ef\"\n",
    "    DATA_PATH = \"data/tfrec/v3/\"\n",
    "    SEED = 1\n",
    "    model_type = \"resnext50_32x4d\"\n",
    "    sample_rate = 44100\n",
    "    n_fft = 1024\n",
    "    win_length = None\n",
    "    hop_length = 512\n",
    "    n_mels = 128\n",
    "    LR_START = 0.000001  # 0.000001\n",
    "    LR_MAX = 0.000005  # 0.00001\n",
    "    LR_MIN = 0.0000001  # 0.000001\n",
    "    LR_RAMP = 4\n",
    "    SAVE_DIR = \"../input/bird-clief-comp-v4-sed\"\n",
    "    RESUME = False\n",
    "    RESUME_EPOCH = 0\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.229, 0.224, 0.225]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a331b9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T03:44:15.275354Z",
     "iopub.status.busy": "2022-05-24T03:44:15.275162Z",
     "iopub.status.idle": "2022-05-24T03:44:15.280543Z",
     "shell.execute_reply": "2022-05-24T03:44:15.279923Z"
    },
    "papermill": {
     "duration": 0.034593,
     "end_time": "2022-05-24T03:44:15.282514",
     "exception": false,
     "start_time": "2022-05-24T03:44:15.247921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./code/utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./code/utils.py\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from config.config import config\n",
    "\n",
    "\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "\n",
    "def decode_image(image_data):\n",
    "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
    "    #image = tf.image.resize(image, [config.IMAGE_SIZE//2, config.IMAGE_SIZE])\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    # normalization\n",
    "    image = image - config.mean  # [0.485, 0.456, 0.406]\n",
    "    image = image / config.std  # [0.229, 0.224, 0.225]\n",
    "    return image\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_label(file_path):\n",
    "    # Convert the path to a list of path components\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    # The second to last is the class-directory\n",
    "    #one_hot = parts[-2] == class_names\n",
    "    # Integer encode the label\n",
    "    return tf.strings.split(parts[-1], '.')[0]\n",
    "\n",
    "def decode_img(img):\n",
    "    # Convert the compressed string to a 3D uint8 tensor\n",
    "    image = tf.io.decode_jpeg(img, channels=3)\n",
    "    # Resize the image to the desired size\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    # normalization\n",
    "    image = image - config.mean  # [0.485, 0.456, 0.406]\n",
    "    image = image / config.std  # [0.229, 0.224, 0.225]\n",
    "    return image\n",
    "\n",
    "def process_path(file_path):\n",
    "    label = get_label(file_path)\n",
    "    # Load the raw data from the file as a string\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "    return img, label\n",
    "\n",
    "def get_eval_dataset():\n",
    "    list_ds = tf.data.Dataset.list_files(str('./test_5sec_mel_spec/*'), shuffle=False)\n",
    "    dataset = list_ds.map(process_path)\n",
    "    dataset = dataset.repeat()  # the training dataset must repeat for several epochs\n",
    "    #dataset = dataset.shuffle(2048)\n",
    "    dataset = dataset.batch(config.BATCH_SIZE, drop_remainder=False, )# num_parallel_calls=AUTO\n",
    "    #dataset = dataset.prefetch(\n",
    "    #AUTO\n",
    "    #)  # prefetch next batch while training (autotune prefetch buffer size)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c9c2718",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T03:44:15.336449Z",
     "iopub.status.busy": "2022-05-24T03:44:15.335973Z",
     "iopub.status.idle": "2022-05-24T03:44:16.004544Z",
     "shell.execute_reply": "2022-05-24T03:44:16.003719Z"
    },
    "papermill": {
     "duration": 0.698024,
     "end_time": "2022-05-24T03:44:16.006754",
     "exception": false,
     "start_time": "2022-05-24T03:44:15.308730",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__notebook__.ipynb  binary_prediction.csv  code  test_5sec_mel_spec\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b66d8ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T03:44:16.063102Z",
     "iopub.status.busy": "2022-05-24T03:44:16.062619Z",
     "iopub.status.idle": "2022-05-24T03:44:16.073181Z",
     "shell.execute_reply": "2022-05-24T03:44:16.072502Z"
    },
    "papermill": {
     "duration": 0.041544,
     "end_time": "2022-05-24T03:44:16.075631",
     "exception": false,
     "start_time": "2022-05-24T03:44:16.034087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing code/train_soundscape_comp_prediction.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/train_soundscape_comp_prediction.py\n",
    "import sys\n",
    "#sys.path.append('./code')\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "from datetime import datetime\n",
    "from config.config import config\n",
    "from utils import *\n",
    "import shutil\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "from tensorflow_addons.losses import SigmoidFocalCrossEntropy\n",
    "import time\n",
    "print(gc.collect())\n",
    "\n",
    "idx_to_bird = {118:'akiapo',\n",
    "125:'aniani',\n",
    "71:'apapan',\n",
    "115:'barpet',\n",
    "150:'crehon',\n",
    "119:'elepai',\n",
    "137:'ercfra',\n",
    "99:'hawama',\n",
    "101:'hawcre',\n",
    "130:'hawgoo',\n",
    "146:'hawhaw',\n",
    "145:'hawpet1',\n",
    "12:'houfin',\n",
    "84:'iiwi',\n",
    "53:'jabwar',\n",
    "151:'maupar',\n",
    "98:'omao',\n",
    "147:'puaioh',\n",
    "1:'skylar',\n",
    "61:'warwhe1',\n",
    "62:'yefcan'}\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n",
    "    # set: this is always the case on Kaggle.\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print(\"Running on TPU \", tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.TPUStrategy(tpu)\n",
    "else:\n",
    "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)\n",
    "config.BATCH_SIZE = config.BATCH_SIZE * strategy.num_replicas_in_sync\n",
    "\n",
    "test_prediction = []\n",
    "test_targets = []\n",
    "test_file = []\n",
    "\n",
    "## get the model for 8 fold\n",
    "\n",
    "def model_get(model, save_dir, folds = 8):\n",
    "    model_list = []\n",
    "    for fold in range(0,folds):#8\n",
    "        model_list.append(tf.keras.models.load_model(model))\n",
    "        _=model_list[fold].load_weights(\n",
    "        save_dir + f'/fold_{fold}/'+ \"weights/\" + \"best.hdf5\",\n",
    "    )  ## work on the path\n",
    "    return model_list\n",
    "\n",
    "#for fold in range(0,10):\n",
    "## model load\n",
    "K.clear_session()\n",
    "print('modle 1')\n",
    "#model_list = model_get(model = \"../input/birdclif-saved-model/comp_v4_SED\",\n",
    "#                      save_dir = \"../input/bird-clief-comp-v4-sed\")\n",
    "\n",
    "print(gc.collect())\n",
    "#model_list = model_list1 + model_list2 + model_list3\n",
    "#model_list = model_list2 + model_list3\n",
    "\n",
    "print('loaded teh models ')\n",
    "test_dataset = get_eval_dataset()\n",
    "actual_count = len(os.listdir('./test_5sec_mel_spec'))\n",
    "\n",
    "test_prediction_fold = []\n",
    "\n",
    "## model 1\n",
    "test_prediction_sub_model_1_0 = []\n",
    "test_prediction_sub_model_1_1 = []\n",
    "test_prediction_sub_model_1_2 = []\n",
    "test_prediction_sub_model_1_3 = []\n",
    "test_prediction_sub_model_1_4 = []\n",
    "test_prediction_sub_model_1_5 = []\n",
    "test_prediction_sub_model_1_6 = []\n",
    "test_prediction_sub_model_1_7 = []\n",
    "\n",
    "## model 2\n",
    "test_prediction_sub_model_2_0 = []\n",
    "test_prediction_sub_model_2_1 = []\n",
    "test_prediction_sub_model_2_2 = []\n",
    "test_prediction_sub_model_2_3 = []\n",
    "test_prediction_sub_model_2_4 = []\n",
    "test_prediction_sub_model_2_5 = []\n",
    "test_prediction_sub_model_2_6 = []\n",
    "test_prediction_sub_model_2_7 = []\n",
    "\n",
    "## model 3\n",
    "test_prediction_sub_model_3_0 = []\n",
    "test_prediction_sub_model_3_1 = []\n",
    "test_prediction_sub_model_3_2 = []\n",
    "test_prediction_sub_model_3_3 = []\n",
    "test_prediction_sub_model_3_4 = []\n",
    "test_prediction_sub_model_3_5 = []\n",
    "test_prediction_sub_model_3_6 = []\n",
    "test_prediction_sub_model_3_7 = []\n",
    "\n",
    "## model 4\n",
    "test_prediction_sub_model_4_0 = []\n",
    "test_prediction_sub_model_4_1 = []\n",
    "test_prediction_sub_model_4_2 = []\n",
    "test_targets_fold = []\n",
    "test_file_fold = []\n",
    "#for rr, m in enumerate(model_list):\n",
    "count = 0\n",
    "#print('model ',rr)\n",
    "test_prediction_sub = []\n",
    "test_targets_sub = []\n",
    "test_file_sub = []\n",
    "\n",
    "\n",
    "model_list1 = model_get(model = \"../input/birdclif-saved-model/comp_v4_SED\",\n",
    "                      save_dir = \"../input/bird-clief-comp-v4-sed\", folds = 3)\n",
    "\n",
    "model_list2 = model_get(model = \"../input/birdclif-saved-model/comp_v9_1_SED\",\n",
    "                      save_dir = \"../input/bird-clief-comp-v9-1-sed\", folds = 3)\n",
    "\n",
    "model_list3 = model_get(model = \"../input/birdclif-saved-model/comp_v8_1_SED\",#convenxt\n",
    "                      save_dir = \"../input/bird-clief-comp-v8-1-sed\", folds = 3)\n",
    "\n",
    "model_list4 = model_get(model = \"../input/birdclif-saved-model/comp_v8_SED\",#convenxt\n",
    "                      save_dir = \"../input/bird-clief-comp-v8-sed/comp_v8_SED\", folds = 3)\n",
    "\n",
    "model_list = model_list1 + model_list2 + model_list3 + model_list4\n",
    "\n",
    "for element in test_dataset:\n",
    "\n",
    "    #pred = m.__call__(element[0])  # , verbose=0)\n",
    "    #test_prediction_sub.append(pred)\n",
    "    test_prediction_sub_model_1_0.append(model_list[0].__call__(element[0]).numpy().astype('float16'))\n",
    "    test_prediction_sub_model_1_1.append(model_list[1].__call__(element[0]).numpy().astype('float16'))\n",
    "    test_prediction_sub_model_1_2.append(model_list[2].__call__(element[0]).numpy().astype('float16'))\n",
    "    \n",
    "    test_prediction_sub_model_2_0.append(model_list[3].__call__(element[0]).numpy().astype('float16'))\n",
    "    test_prediction_sub_model_2_1.append(model_list[4].__call__(element[0]).numpy().astype('float16'))\n",
    "    test_prediction_sub_model_2_2.append(model_list[5].__call__(element[0]).numpy().astype('float16'))\n",
    "    \n",
    "    test_prediction_sub_model_3_0.append(model_list[6].__call__(element[0]).numpy().astype('float16'))\n",
    "    test_prediction_sub_model_3_1.append(model_list[7].__call__(element[0]).numpy().astype('float16'))\n",
    "    test_prediction_sub_model_3_2.append(model_list[8].__call__(element[0]).numpy().astype('float16'))\n",
    "    \n",
    "    test_prediction_sub_model_4_0.append(model_list[9].__call__(element[0]).numpy().astype('float16'))\n",
    "    test_prediction_sub_model_4_1.append(model_list[10].__call__(element[0]).numpy().astype('float16'))\n",
    "    test_prediction_sub_model_4_2.append(model_list[11].__call__(element[0]).numpy().astype('float16'))\n",
    "    \n",
    "    test_file_sub.append(element[1].numpy())\n",
    "    \n",
    "    if count * config.BATCH_SIZE > actual_count + 20:  # this 20 is for safty\n",
    "        print('the break ',count * config.BATCH_SIZE)\n",
    "        break\n",
    "    print('the out ',count * config.BATCH_SIZE)\n",
    "    count += 1\n",
    "    \n",
    "del model_list\n",
    "print(gc.collect())\n",
    "print('going to sleep')\n",
    "time.sleep(20)\n",
    "\n",
    "test_prediction_fold.append(np.concatenate(test_prediction_sub_model_1_0)[:actual_count])\n",
    "test_prediction_fold.append(np.concatenate(test_prediction_sub_model_1_1)[:actual_count])\n",
    "test_prediction_fold.append(np.concatenate(test_prediction_sub_model_1_2)[:actual_count])\n",
    "\n",
    "\n",
    "test_prediction_fold.append(np.concatenate(test_prediction_sub_model_2_0)[:actual_count])\n",
    "test_prediction_fold.append(np.concatenate(test_prediction_sub_model_2_1)[:actual_count])\n",
    "test_prediction_fold.append(np.concatenate(test_prediction_sub_model_2_2)[:actual_count])\n",
    "\n",
    "\n",
    "test_prediction_fold.append(np.concatenate(test_prediction_sub_model_3_0)[:actual_count])\n",
    "test_prediction_fold.append(np.concatenate(test_prediction_sub_model_3_1)[:actual_count])\n",
    "test_prediction_fold.append(np.concatenate(test_prediction_sub_model_3_2)[:actual_count])\n",
    "\n",
    "test_prediction_fold.append(np.concatenate(test_prediction_sub_model_4_0)[:actual_count])\n",
    "test_prediction_fold.append(np.concatenate(test_prediction_sub_model_4_1)[:actual_count])\n",
    "test_prediction_fold.append(np.concatenate(test_prediction_sub_model_4_2)[:actual_count])\n",
    "\n",
    "#test_targets_fold.append(np.concatenate(test_targets_sub)[:actual_count])\n",
    "test_file_fold.append(np.concatenate(test_file_sub)[:actual_count])\n",
    "\n",
    "test_prediction = np.array(test_prediction_fold).squeeze().mean(axis=0)\n",
    "#test_targets = test_targets_fold[0]\n",
    "test_file = test_file_fold[0]\n",
    "\n",
    "\n",
    "oof_dict = {\n",
    "\n",
    "    'itemid':test_file,\n",
    "    #'hasbird':test_targets,\n",
    "\n",
    "}\n",
    "\n",
    "for i in range(0, config.N_CLASSES):\n",
    "    oof_dict[i] = test_prediction[:,i]\n",
    "\n",
    "oof_df = pd.DataFrame.from_dict(oof_dict)\n",
    "oof_df['itemid'] =  oof_df['itemid'].map(lambda x: x.decode(\"utf-8\")) \n",
    "\n",
    "## retain the unwanted birds\n",
    "oof_df = oof_df.filter(items=list(idx_to_bird.keys())+['itemid'])\n",
    "\n",
    "oof_df.to_csv(f\"comp_prediction.csv\", index = False)\n",
    "\n",
    "## 5 sec\n",
    "## happywhale-tfrev-train-sound-v2\n",
    "## gs://kds-22c2720af882134066efd729205635efc3a6ce12dfa19de78bd41475\n",
    "\n",
    "## 10 sec\n",
    "## happywhale-tfrev-train-sound-v1\n",
    "## gs://kds-168dba29a1eb377402725ff4ec9b4a8afa032dfacaa1f1b84639cc59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f26d245",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T03:44:16.131499Z",
     "iopub.status.busy": "2022-05-24T03:44:16.131025Z",
     "iopub.status.idle": "2022-05-24T03:44:16.134240Z",
     "shell.execute_reply": "2022-05-24T03:44:16.133581Z"
    },
    "papermill": {
     "duration": 0.03251,
     "end_time": "2022-05-24T03:44:16.135863",
     "exception": false,
     "start_time": "2022-05-24T03:44:16.103353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!sleep 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26b3231e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T03:44:16.191341Z",
     "iopub.status.busy": "2022-05-24T03:44:16.190831Z",
     "iopub.status.idle": "2022-05-24T03:49:28.940542Z",
     "shell.execute_reply": "2022-05-24T03:49:28.939681Z"
    },
    "papermill": {
     "duration": 312.779959,
     "end_time": "2022-05-24T03:49:28.942872",
     "exception": false,
     "start_time": "2022-05-24T03:44:16.162913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\r\n",
      "REPLICAS:  1\r\n",
      "modle 1\r\n",
      "0\r\n",
      "loaded teh models \r\n",
      "2022-05-24 03:44:20.438431: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n",
      "2022-05-24 03:44:20.474414: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n",
      "2022-05-24 03:44:20.475258: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n",
      "2022-05-24 03:44:20.476224: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\r\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n",
      "2022-05-24 03:44:20.476571: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n",
      "2022-05-24 03:44:20.477366: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n",
      "2022-05-24 03:44:20.478102: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n",
      "2022-05-24 03:44:21.092943: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n",
      "2022-05-24 03:44:21.093888: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n",
      "2022-05-24 03:44:21.094658: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n",
      "2022-05-24 03:44:21.095341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\r\n",
      "/opt/conda/lib/python3.7/site-packages/keras/layers/core.py:1045: UserWarning: model is not loaded, but a Lambda layer uses it. It may cause errors.\r\n",
      "  , UserWarning)\r\n",
      "2022-05-24 03:48:00.046623: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\r\n",
      "2022-05-24 03:48:01.496077: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\r\n",
      "the out  0\r\n",
      "the out  16\r\n",
      "the out  32\r\n",
      "the break  48\r\n",
      "3322\r\n",
      "going to sleep\r\n"
     ]
    }
   ],
   "source": [
    "!python code/train_soundscape_comp_prediction.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55604116",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T03:49:29.012562Z",
     "iopub.status.busy": "2022-05-24T03:49:29.011803Z",
     "iopub.status.idle": "2022-05-24T03:49:29.142745Z",
     "shell.execute_reply": "2022-05-24T03:49:29.142051Z"
    },
    "papermill": {
     "duration": 0.168698,
     "end_time": "2022-05-24T03:49:29.145210",
     "exception": false,
     "start_time": "2022-05-24T03:49:28.976512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "print(gc.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87bc74b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T03:49:29.211418Z",
     "iopub.status.busy": "2022-05-24T03:49:29.211199Z",
     "iopub.status.idle": "2022-05-24T03:49:29.214543Z",
     "shell.execute_reply": "2022-05-24T03:49:29.213807Z"
    },
    "papermill": {
     "duration": 0.038295,
     "end_time": "2022-05-24T03:49:29.216570",
     "exception": false,
     "start_time": "2022-05-24T03:49:29.178275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!sync; echo 3 > /proc/sys/vm/drop_caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96f8ed84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T03:49:29.281138Z",
     "iopub.status.busy": "2022-05-24T03:49:29.280605Z",
     "iopub.status.idle": "2022-05-24T03:49:29.287857Z",
     "shell.execute_reply": "2022-05-24T03:49:29.287179Z"
    },
    "papermill": {
     "duration": 0.042247,
     "end_time": "2022-05-24T03:49:29.290149",
     "exception": false,
     "start_time": "2022-05-24T03:49:29.247902",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float16')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array([1.0]).astype('float16').dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1e839f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T03:49:29.354730Z",
     "iopub.status.busy": "2022-05-24T03:49:29.354015Z",
     "iopub.status.idle": "2022-05-24T03:49:29.359696Z",
     "shell.execute_reply": "2022-05-24T03:49:29.359093Z"
    },
    "papermill": {
     "duration": 0.039869,
     "end_time": "2022-05-24T03:49:29.361323",
     "exception": false,
     "start_time": "2022-05-24T03:49:29.321454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx_to_bird = {118:'akiapo',\n",
    "125:'aniani',\n",
    "71:'apapan',\n",
    "115:'barpet',\n",
    "150:'crehon',\n",
    "119:'elepai',\n",
    "137:'ercfra',\n",
    "99:'hawama',\n",
    "101:'hawcre',\n",
    "130:'hawgoo',\n",
    "146:'hawhaw',\n",
    "145:'hawpet1',\n",
    "12:'houfin',\n",
    "84:'iiwi',\n",
    "53:'jabwar',\n",
    "151:'maupar',\n",
    "98:'omao',\n",
    "147:'puaioh',\n",
    "1:'skylar',\n",
    "61:'warwhe1',\n",
    "62:'yefcan'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d15c89ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T03:49:29.425074Z",
     "iopub.status.busy": "2022-05-24T03:49:29.424465Z",
     "iopub.status.idle": "2022-05-24T03:49:29.477288Z",
     "shell.execute_reply": "2022-05-24T03:49:29.474420Z"
    },
    "papermill": {
     "duration": 0.087296,
     "end_time": "2022-05-24T03:49:29.479758",
     "exception": false,
     "start_time": "2022-05-24T03:49:29.392462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "binary_df = pd.read_csv('./binary_prediction.csv')\n",
    "comp_df = pd.read_csv('./comp_prediction.csv')\n",
    "#comp_df.head()\n",
    "\n",
    "bird_threshold = 0.4\n",
    "ind_bird_threshold = 0.05\n",
    "#binary_df = binary_df[binary_df['prediction']> bird_threshold]\n",
    "\n",
    "binary_df = binary_df[binary_df['prediction']> binary_df['prediction'].quantile(0.10)]\n",
    "\n",
    "comp1_df = comp_df[comp_df['itemid'].isin(binary_df['itemid'].values)]\n",
    "for i in idx_to_bird.keys():\n",
    "    comp1_df[str(i)] = comp1_df[str(i)]>comp_df[str(i)].median()#quantile(0.60)\n",
    "non_comp_df = comp_df[~comp_df['itemid'].isin(binary_df['itemid'].values)]\n",
    "for i in idx_to_bird.keys():\n",
    "    non_comp_df[str(i)] = non_comp_df[str(i)]>1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5fff7e39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T03:49:29.552782Z",
     "iopub.status.busy": "2022-05-24T03:49:29.552077Z",
     "iopub.status.idle": "2022-05-24T03:49:29.567215Z",
     "shell.execute_reply": "2022-05-24T03:49:29.566465Z"
    },
    "papermill": {
     "duration": 0.053098,
     "end_time": "2022-05-24T03:49:29.569124",
     "exception": false,
     "start_time": "2022-05-24T03:49:29.516026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "row_id_list = []\n",
    "target_list = []\n",
    "\n",
    "for index, row in comp1_df.iterrows():\n",
    "    for i in idx_to_bird.items():\n",
    "        row_id_list.append(row['itemid'].replace('sec',str(i[1])))\n",
    "        target_list.append(row[str(i[0])])\n",
    "\n",
    "for index, row in non_comp_df.iterrows():\n",
    "    for i in idx_to_bird.items():\n",
    "        row_id_list.append(row['itemid'].replace('sec',str(i[1])))\n",
    "        target_list.append(row[str(i[0])])\n",
    "        \n",
    "submission_df = pd.DataFrame.from_dict({'row_id':row_id_list, 'target':target_list})\n",
    "submission_df.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75116825",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T03:49:29.639596Z",
     "iopub.status.busy": "2022-05-24T03:49:29.638996Z",
     "iopub.status.idle": "2022-05-24T03:49:29.652576Z",
     "shell.execute_reply": "2022-05-24T03:49:29.651813Z"
    },
    "papermill": {
     "duration": 0.049631,
     "end_time": "2022-05-24T03:49:29.654333",
     "exception": false,
     "start_time": "2022-05-24T03:49:29.604702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>soundscape_453028782_akiapo_10</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>soundscape_453028782_aniani_10</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>soundscape_453028782_apapan_10</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>soundscape_453028782_barpet_10</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>soundscape_453028782_crehon_10</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>soundscape_453028782_omao_45</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>soundscape_453028782_puaioh_45</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>soundscape_453028782_skylar_45</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>soundscape_453028782_warwhe1_45</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>soundscape_453028782_yefcan_45</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              row_id  target\n",
       "0     soundscape_453028782_akiapo_10    True\n",
       "1     soundscape_453028782_aniani_10    True\n",
       "2     soundscape_453028782_apapan_10   False\n",
       "3     soundscape_453028782_barpet_10    True\n",
       "4     soundscape_453028782_crehon_10   False\n",
       "..                               ...     ...\n",
       "247     soundscape_453028782_omao_45   False\n",
       "248   soundscape_453028782_puaioh_45   False\n",
       "249   soundscape_453028782_skylar_45   False\n",
       "250  soundscape_453028782_warwhe1_45   False\n",
       "251   soundscape_453028782_yefcan_45   False\n",
       "\n",
       "[252 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11d9e7aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T03:49:29.721328Z",
     "iopub.status.busy": "2022-05-24T03:49:29.720817Z",
     "iopub.status.idle": "2022-05-24T03:49:29.723704Z",
     "shell.execute_reply": "2022-05-24T03:49:29.723098Z"
    },
    "papermill": {
     "duration": 0.037774,
     "end_time": "2022-05-24T03:49:29.725357",
     "exception": false,
     "start_time": "2022-05-24T03:49:29.687583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#comp_df = pd.read_csv('./comp_prediction.csv')\n",
    "#comp_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 559.669218,
   "end_time": "2022-05-24T03:49:30.276567",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-05-24T03:40:10.607349",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
