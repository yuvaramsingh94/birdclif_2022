{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6977cc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd524136",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D,\n",
    "    BatchNormalization,\n",
    "    ReLU,\n",
    "    GlobalAveragePooling2D,\n",
    "    Dense,\n",
    "    Softmax,\n",
    ")\n",
    "from kapre import STFT, Magnitude, MagnitudeToDecibel\n",
    "from kapre.composed import get_melspectrogram_layer, get_log_frequency_spectrogram_layer\n",
    "import tensorflow as tf\n",
    "import tfimm\n",
    "from config.config import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe1b82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttBlockV2(nn.Module):\n",
    "    def __init__(self, in_features: int, out_features: int, activation=\"linear\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = activation\n",
    "        self.att = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True,\n",
    "        )\n",
    "        self.cla = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True,\n",
    "        )\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        init_layer(self.att)\n",
    "        init_layer(self.cla)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (n_samples, n_in, n_time)\n",
    "        norm_att = torch.softmax(torch.tanh(self.att(x)), dim=-1)\n",
    "        cla = self.nonlinear_transform(self.cla(x))\n",
    "        x = torch.sum(norm_att * cla, dim=2)\n",
    "        return x, norm_att, cla\n",
    "\n",
    "    def nonlinear_transform(self, x):\n",
    "        if self.activation == \"linear\":\n",
    "            return x\n",
    "        elif self.activation == \"sigmoid\":\n",
    "            return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a5f232b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_frame = 1000  ## simply\n",
    "freq = 128\n",
    "n_classes = 2\n",
    "\n",
    "\n",
    "def get_model():\n",
    "\n",
    "    # with strategy.scope():\n",
    "\n",
    "    base = tfimm.create_model(config.model_type, pretrained=True, nb_classes=0)\n",
    "\n",
    "    input = tf.keras.Input((freq, time_frame, 3), name=\"inp1\")\n",
    "    _, features = base(input, return_features=True)\n",
    "\n",
    "    ## SED model flow\n",
    "    # (batch_size, freq, frames, channels, )\n",
    "\n",
    "    # (batch_size, frames, channels, )\n",
    "    freq_reduced = tf.keras.layers.Lambda(\n",
    "        lambda x: tf.math.reduce_mean(x, axis=1), output_shape=None\n",
    "    )(features[\"features\"])\n",
    "    ## without pooling\n",
    "    # ap = tf.keras.layers.AveragePooling1D(pool_size=2,strides=1,)(freq_reduced)\n",
    "\n",
    "    dd = tf.keras.layers.Dense(2048)(freq_reduced)\n",
    "\n",
    "    ## Starting with the attention block\n",
    "    att = tf.keras.layers.Conv1D(\n",
    "        2,\n",
    "        1,\n",
    "        strides=1,\n",
    "        padding=\"valid\",\n",
    "    )(dd)\n",
    "    att_aten = tf.keras.layers.Lambda(\n",
    "        lambda x: tf.keras.activations.softmax(tf.keras.activations.tanh(x)),\n",
    "        output_shape=None,\n",
    "    )(att)\n",
    "    cla = tf.keras.layers.Conv1D(\n",
    "        2,\n",
    "        1,\n",
    "        strides=1,\n",
    "        padding=\"valid\",\n",
    "    )(dd)\n",
    "    cla_aten = tf.keras.layers.Lambda(\n",
    "        lambda x: tf.keras.activations.sigmoid(x), output_shape=None\n",
    "    )(cla)\n",
    "\n",
    "    x = att_aten * cla_aten\n",
    "    x = tf.keras.layers.Lambda(\n",
    "        lambda x: tf.math.reduce_sum(x, axis=1), output_shape=None\n",
    "    )(x)\n",
    "\n",
    "    # model = tf.keras.models.Model(inputs=input, outputs=[x, att_aten, cla_aten])\n",
    "    model = tf.keras.models.Model(inputs=input, outputs=x)\n",
    "    # model = tf.keras.models.Model(inputs=input, outputs=logits)\n",
    "    model.summary()\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=config.LR_START)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=opt,\n",
    "        # loss=[tf.keras.losses.SparseCategoricalCrossentropy()],\n",
    "        loss={\n",
    "            \"logits\": tf.keras.losses.CategoricalCrossentropy(\n",
    "                from_logits=True, label_smoothing=0.1\n",
    "            ),\n",
    "        },\n",
    "        # metrics=[\n",
    "        #    # tf.keras.metrics.SparseCategoricalAccuracy(),\n",
    "        #    # tf.keras.metrics.SparseTopKCategoricalAccuracy(k=5),\n",
    "        #    tf.keras.metrics.CategoricalAccuracy(),\n",
    "        #    tf.keras.metrics.TopKCategoricalAccuracy(k=5),\n",
    "        # ],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "080140c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing ResNet.\n",
      "All the weights of ResNet were initialized from the PyTorch model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_16\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inp1 (InputLayer)               [(None, 128, 1000, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "res_net_37 (ResNet)             ((None, 2048), {'ste 23561152    inp1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_34 (Lambda)              (None, 32, 2048)     0           res_net_37[0][17]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 32, 2048)     4196352     lambda_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 32, 2)        4098        dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 32, 2)        4098        dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_35 (Lambda)              (None, 32, 2)        0           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_36 (Lambda)              (None, 32, 2)        0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_7 (TFOpLambda) (None, 32, 2)        0           lambda_35[0][0]                  \n",
      "                                                                 lambda_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_37 (Lambda)              (None, 2)            0           tf.math.multiply_7[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 27,765,700\n",
      "Trainable params: 27,712,580\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "262fc673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 128, 1000, 3])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.uniform(shape=[2, 128, 1000, 3]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cbe12610",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(tf.random.uniform(shape=[2, 128, 1000, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f883e66c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[6.4271836, 8.568943 ],\n",
       "       [6.4548607, 8.613371 ]], dtype=float32)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3fd48a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing ResNet.\n",
      "All the weights of ResNet were initialized from the PyTorch model.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base = tfimm.create_model(config.model_type, pretrained=True, nb_classes=0)\n",
    "input = tf.keras.Input((freq, time_frame, 3), name=\"inp1\")\n",
    "_, features = base(input, return_features=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6ef52d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stem': <KerasTensor: shape=(None, 32, 250, 64) dtype=float32 (created by layer 'res_net_5')>,\n",
       " 'block_0': <KerasTensor: shape=(None, 32, 250, 256) dtype=float32 (created by layer 'res_net_5')>,\n",
       " 'block_1': <KerasTensor: shape=(None, 32, 250, 256) dtype=float32 (created by layer 'res_net_5')>,\n",
       " 'block_2': <KerasTensor: shape=(None, 32, 250, 256) dtype=float32 (created by layer 'res_net_5')>,\n",
       " 'block_3': <KerasTensor: shape=(None, 16, 125, 512) dtype=float32 (created by layer 'res_net_5')>,\n",
       " 'block_4': <KerasTensor: shape=(None, 16, 125, 512) dtype=float32 (created by layer 'res_net_5')>,\n",
       " 'block_5': <KerasTensor: shape=(None, 16, 125, 512) dtype=float32 (created by layer 'res_net_5')>,\n",
       " 'block_6': <KerasTensor: shape=(None, 16, 125, 512) dtype=float32 (created by layer 'res_net_5')>,\n",
       " 'block_7': <KerasTensor: shape=(None, 8, 63, 1024) dtype=float32 (created by layer 'res_net_5')>,\n",
       " 'block_8': <KerasTensor: shape=(None, 8, 63, 1024) dtype=float32 (created by layer 'res_net_5')>,\n",
       " 'block_9': <KerasTensor: shape=(None, 8, 63, 1024) dtype=float32 (created by layer 'res_net_5')>,\n",
       " 'block_10': <KerasTensor: shape=(None, 8, 63, 1024) dtype=float32 (created by layer 'res_net_5')>,\n",
       " 'block_11': <KerasTensor: shape=(None, 8, 63, 1024) dtype=float32 (created by layer 'res_net_5')>,\n",
       " 'block_12': <KerasTensor: shape=(None, 8, 63, 1024) dtype=float32 (created by layer 'res_net_5')>,\n",
       " 'block_13': <KerasTensor: shape=(None, 4, 32, 2048) dtype=float32 (created by layer 'res_net_5')>,\n",
       " 'block_14': <KerasTensor: shape=(None, 4, 32, 2048) dtype=float32 (created by layer 'res_net_5')>,\n",
       " 'block_15': <KerasTensor: shape=(None, 4, 32, 2048) dtype=float32 (created by layer 'res_net_5')>,\n",
       " 'features': <KerasTensor: shape=(None, 4, 32, 2048) dtype=float32 (created by layer 'res_net_5')>,\n",
       " 'logits': <KerasTensor: shape=(None, 2048) dtype=float32 (created by layer 'res_net_5')>}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
