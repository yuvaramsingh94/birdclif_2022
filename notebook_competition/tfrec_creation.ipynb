{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1391c62",
   "metadata": {},
   "source": [
    "## basic work\n",
    "\n",
    "make a Tf record with \n",
    "- 10 sec mel spectrogram\n",
    "- primary label\n",
    "- secondary label\n",
    "- prediction\n",
    "- rating\n",
    "- lat & long\n",
    "\n",
    "Next steps\n",
    "- call type\n",
    "- time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "593fd594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from joblib import delayed, Parallel\n",
    "import pandas as pd\n",
    "\n",
    "import os, json, random\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf, re, math\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "951ef895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemid</th>\n",
       "      <th>hasbird</th>\n",
       "      <th>prediction</th>\n",
       "      <th>song_name</th>\n",
       "      <th>primary_label</th>\n",
       "      <th>secondary_labels</th>\n",
       "      <th>type</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>scientific_name</th>\n",
       "      <th>common_name</th>\n",
       "      <th>author</th>\n",
       "      <th>license</th>\n",
       "      <th>rating</th>\n",
       "      <th>time</th>\n",
       "      <th>url</th>\n",
       "      <th>filename</th>\n",
       "      <th>primary_label_index</th>\n",
       "      <th>secondary_label_index</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/librosa/competition/v1/10_sec/moudov/X...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.941831</td>\n",
       "      <td>moudov/XC138056</td>\n",
       "      <td>moudov</td>\n",
       "      <td>[]</td>\n",
       "      <td>['nest-coo pair at potential nest-site']</td>\n",
       "      <td>40.1226</td>\n",
       "      <td>-75.0635</td>\n",
       "      <td>Zenaida macroura</td>\n",
       "      <td>Mourning Dove</td>\n",
       "      <td>Paul Driver</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>09:00</td>\n",
       "      <td>https://www.xeno-canto.org/138056</td>\n",
       "      <td>moudov/XC138056.ogg</td>\n",
       "      <td>33</td>\n",
       "      <td>[]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/librosa/competition/v1/10_sec/moudov/X...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.857844</td>\n",
       "      <td>moudov/XC138056</td>\n",
       "      <td>moudov</td>\n",
       "      <td>[]</td>\n",
       "      <td>['nest-coo pair at potential nest-site']</td>\n",
       "      <td>40.1226</td>\n",
       "      <td>-75.0635</td>\n",
       "      <td>Zenaida macroura</td>\n",
       "      <td>Mourning Dove</td>\n",
       "      <td>Paul Driver</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>09:00</td>\n",
       "      <td>https://www.xeno-canto.org/138056</td>\n",
       "      <td>moudov/XC138056.ogg</td>\n",
       "      <td>33</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/librosa/competition/v1/10_sec/moudov/X...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.905810</td>\n",
       "      <td>moudov/XC138056</td>\n",
       "      <td>moudov</td>\n",
       "      <td>[]</td>\n",
       "      <td>['nest-coo pair at potential nest-site']</td>\n",
       "      <td>40.1226</td>\n",
       "      <td>-75.0635</td>\n",
       "      <td>Zenaida macroura</td>\n",
       "      <td>Mourning Dove</td>\n",
       "      <td>Paul Driver</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>09:00</td>\n",
       "      <td>https://www.xeno-canto.org/138056</td>\n",
       "      <td>moudov/XC138056.ogg</td>\n",
       "      <td>33</td>\n",
       "      <td>[]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/librosa/competition/v1/10_sec/moudov/X...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.823133</td>\n",
       "      <td>moudov/XC138056</td>\n",
       "      <td>moudov</td>\n",
       "      <td>[]</td>\n",
       "      <td>['nest-coo pair at potential nest-site']</td>\n",
       "      <td>40.1226</td>\n",
       "      <td>-75.0635</td>\n",
       "      <td>Zenaida macroura</td>\n",
       "      <td>Mourning Dove</td>\n",
       "      <td>Paul Driver</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>09:00</td>\n",
       "      <td>https://www.xeno-canto.org/138056</td>\n",
       "      <td>moudov/XC138056.ogg</td>\n",
       "      <td>33</td>\n",
       "      <td>[]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/librosa/competition/v1/10_sec/moudov/X...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.812675</td>\n",
       "      <td>moudov/XC138056</td>\n",
       "      <td>moudov</td>\n",
       "      <td>[]</td>\n",
       "      <td>['nest-coo pair at potential nest-site']</td>\n",
       "      <td>40.1226</td>\n",
       "      <td>-75.0635</td>\n",
       "      <td>Zenaida macroura</td>\n",
       "      <td>Mourning Dove</td>\n",
       "      <td>Paul Driver</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>09:00</td>\n",
       "      <td>https://www.xeno-canto.org/138056</td>\n",
       "      <td>moudov/XC138056.ogg</td>\n",
       "      <td>33</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              itemid  hasbird  prediction  \\\n",
       "0  ../data/librosa/competition/v1/10_sec/moudov/X...        0    0.941831   \n",
       "1  ../data/librosa/competition/v1/10_sec/moudov/X...        0    0.857844   \n",
       "2  ../data/librosa/competition/v1/10_sec/moudov/X...        0    0.905810   \n",
       "3  ../data/librosa/competition/v1/10_sec/moudov/X...        0    0.823133   \n",
       "4  ../data/librosa/competition/v1/10_sec/moudov/X...        0    0.812675   \n",
       "\n",
       "         song_name primary_label secondary_labels  \\\n",
       "0  moudov/XC138056        moudov               []   \n",
       "1  moudov/XC138056        moudov               []   \n",
       "2  moudov/XC138056        moudov               []   \n",
       "3  moudov/XC138056        moudov               []   \n",
       "4  moudov/XC138056        moudov               []   \n",
       "\n",
       "                                       type  latitude  longitude  \\\n",
       "0  ['nest-coo pair at potential nest-site']   40.1226   -75.0635   \n",
       "1  ['nest-coo pair at potential nest-site']   40.1226   -75.0635   \n",
       "2  ['nest-coo pair at potential nest-site']   40.1226   -75.0635   \n",
       "3  ['nest-coo pair at potential nest-site']   40.1226   -75.0635   \n",
       "4  ['nest-coo pair at potential nest-site']   40.1226   -75.0635   \n",
       "\n",
       "    scientific_name    common_name       author  \\\n",
       "0  Zenaida macroura  Mourning Dove  Paul Driver   \n",
       "1  Zenaida macroura  Mourning Dove  Paul Driver   \n",
       "2  Zenaida macroura  Mourning Dove  Paul Driver   \n",
       "3  Zenaida macroura  Mourning Dove  Paul Driver   \n",
       "4  Zenaida macroura  Mourning Dove  Paul Driver   \n",
       "\n",
       "                                             license  rating   time  \\\n",
       "0  Creative Commons Attribution-NonCommercial-Sha...     4.0  09:00   \n",
       "1  Creative Commons Attribution-NonCommercial-Sha...     4.0  09:00   \n",
       "2  Creative Commons Attribution-NonCommercial-Sha...     4.0  09:00   \n",
       "3  Creative Commons Attribution-NonCommercial-Sha...     4.0  09:00   \n",
       "4  Creative Commons Attribution-NonCommercial-Sha...     4.0  09:00   \n",
       "\n",
       "                                 url             filename  \\\n",
       "0  https://www.xeno-canto.org/138056  moudov/XC138056.ogg   \n",
       "1  https://www.xeno-canto.org/138056  moudov/XC138056.ogg   \n",
       "2  https://www.xeno-canto.org/138056  moudov/XC138056.ogg   \n",
       "3  https://www.xeno-canto.org/138056  moudov/XC138056.ogg   \n",
       "4  https://www.xeno-canto.org/138056  moudov/XC138056.ogg   \n",
       "\n",
       "   primary_label_index secondary_label_index  fold  \n",
       "0                   33                    []     3  \n",
       "1                   33                    []     0  \n",
       "2                   33                    []     7  \n",
       "3                   33                    []     4  \n",
       "4                   33                    []     0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df = pd.read_csv(\n",
    "    \"../prediction/binary_v3_SED/train_competition_v1_binary_merged.csv\"\n",
    ")\n",
    "main_df[\"secondary_label_index\"] = main_df[\"secondary_label_index\"].apply(eval)\n",
    "main_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0628e4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fold(fold):\n",
    "    val_df = main_df[main_df.fold == fold].reset_index(drop=True)\n",
    "    return val_df\n",
    "\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy()  # BytesList won't unpack a string from an EagerTensor.\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def _float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    if type(value) == list:\n",
    "        return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "10 sec mel spectrogram\n",
    "primary label\n",
    "secondary label\n",
    "prediction\n",
    "rating\n",
    "lat & long\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def serialize_example(\n",
    "    image, image_name, primary_label, secondary_label, prediction, rating, lat, long\n",
    "):\n",
    "    feature = {\n",
    "        \"image\": _bytes_feature(image),\n",
    "        \"image_name\": _bytes_feature(image_name),\n",
    "        \"primary_label\": _int64_feature(primary_label),\n",
    "        \"secondary_label\": _int64_feature(secondary_label),\n",
    "        \"prediction\": _float_feature(prediction),\n",
    "        \"rating\": _float_feature(rating),\n",
    "        \"lat\": _float_feature(lat),\n",
    "        \"long\": _float_feature(long),\n",
    "    }\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto.SerializeToString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef3d01d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemid</th>\n",
       "      <th>hasbird</th>\n",
       "      <th>prediction</th>\n",
       "      <th>song_name</th>\n",
       "      <th>primary_label</th>\n",
       "      <th>secondary_labels</th>\n",
       "      <th>type</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>scientific_name</th>\n",
       "      <th>common_name</th>\n",
       "      <th>author</th>\n",
       "      <th>license</th>\n",
       "      <th>rating</th>\n",
       "      <th>time</th>\n",
       "      <th>url</th>\n",
       "      <th>filename</th>\n",
       "      <th>primary_label_index</th>\n",
       "      <th>secondary_label_index</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/librosa/competition/v1/10_sec/moudov/X...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.941831</td>\n",
       "      <td>moudov/XC138056</td>\n",
       "      <td>moudov</td>\n",
       "      <td>[]</td>\n",
       "      <td>['nest-coo pair at potential nest-site']</td>\n",
       "      <td>40.1226</td>\n",
       "      <td>-75.0635</td>\n",
       "      <td>Zenaida macroura</td>\n",
       "      <td>Mourning Dove</td>\n",
       "      <td>Paul Driver</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>09:00</td>\n",
       "      <td>https://www.xeno-canto.org/138056</td>\n",
       "      <td>moudov/XC138056.ogg</td>\n",
       "      <td>33</td>\n",
       "      <td>[]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/librosa/competition/v1/10_sec/moudov/X...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.857844</td>\n",
       "      <td>moudov/XC138056</td>\n",
       "      <td>moudov</td>\n",
       "      <td>[]</td>\n",
       "      <td>['nest-coo pair at potential nest-site']</td>\n",
       "      <td>40.1226</td>\n",
       "      <td>-75.0635</td>\n",
       "      <td>Zenaida macroura</td>\n",
       "      <td>Mourning Dove</td>\n",
       "      <td>Paul Driver</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>09:00</td>\n",
       "      <td>https://www.xeno-canto.org/138056</td>\n",
       "      <td>moudov/XC138056.ogg</td>\n",
       "      <td>33</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/librosa/competition/v1/10_sec/moudov/X...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.905810</td>\n",
       "      <td>moudov/XC138056</td>\n",
       "      <td>moudov</td>\n",
       "      <td>[]</td>\n",
       "      <td>['nest-coo pair at potential nest-site']</td>\n",
       "      <td>40.1226</td>\n",
       "      <td>-75.0635</td>\n",
       "      <td>Zenaida macroura</td>\n",
       "      <td>Mourning Dove</td>\n",
       "      <td>Paul Driver</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>09:00</td>\n",
       "      <td>https://www.xeno-canto.org/138056</td>\n",
       "      <td>moudov/XC138056.ogg</td>\n",
       "      <td>33</td>\n",
       "      <td>[]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/librosa/competition/v1/10_sec/moudov/X...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.823133</td>\n",
       "      <td>moudov/XC138056</td>\n",
       "      <td>moudov</td>\n",
       "      <td>[]</td>\n",
       "      <td>['nest-coo pair at potential nest-site']</td>\n",
       "      <td>40.1226</td>\n",
       "      <td>-75.0635</td>\n",
       "      <td>Zenaida macroura</td>\n",
       "      <td>Mourning Dove</td>\n",
       "      <td>Paul Driver</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>09:00</td>\n",
       "      <td>https://www.xeno-canto.org/138056</td>\n",
       "      <td>moudov/XC138056.ogg</td>\n",
       "      <td>33</td>\n",
       "      <td>[]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/librosa/competition/v1/10_sec/moudov/X...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.812675</td>\n",
       "      <td>moudov/XC138056</td>\n",
       "      <td>moudov</td>\n",
       "      <td>[]</td>\n",
       "      <td>['nest-coo pair at potential nest-site']</td>\n",
       "      <td>40.1226</td>\n",
       "      <td>-75.0635</td>\n",
       "      <td>Zenaida macroura</td>\n",
       "      <td>Mourning Dove</td>\n",
       "      <td>Paul Driver</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>09:00</td>\n",
       "      <td>https://www.xeno-canto.org/138056</td>\n",
       "      <td>moudov/XC138056.ogg</td>\n",
       "      <td>33</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              itemid  hasbird  prediction  \\\n",
       "0  ../data/librosa/competition/v1/10_sec/moudov/X...        0    0.941831   \n",
       "1  ../data/librosa/competition/v1/10_sec/moudov/X...        0    0.857844   \n",
       "2  ../data/librosa/competition/v1/10_sec/moudov/X...        0    0.905810   \n",
       "3  ../data/librosa/competition/v1/10_sec/moudov/X...        0    0.823133   \n",
       "4  ../data/librosa/competition/v1/10_sec/moudov/X...        0    0.812675   \n",
       "\n",
       "         song_name primary_label secondary_labels  \\\n",
       "0  moudov/XC138056        moudov               []   \n",
       "1  moudov/XC138056        moudov               []   \n",
       "2  moudov/XC138056        moudov               []   \n",
       "3  moudov/XC138056        moudov               []   \n",
       "4  moudov/XC138056        moudov               []   \n",
       "\n",
       "                                       type  latitude  longitude  \\\n",
       "0  ['nest-coo pair at potential nest-site']   40.1226   -75.0635   \n",
       "1  ['nest-coo pair at potential nest-site']   40.1226   -75.0635   \n",
       "2  ['nest-coo pair at potential nest-site']   40.1226   -75.0635   \n",
       "3  ['nest-coo pair at potential nest-site']   40.1226   -75.0635   \n",
       "4  ['nest-coo pair at potential nest-site']   40.1226   -75.0635   \n",
       "\n",
       "    scientific_name    common_name       author  \\\n",
       "0  Zenaida macroura  Mourning Dove  Paul Driver   \n",
       "1  Zenaida macroura  Mourning Dove  Paul Driver   \n",
       "2  Zenaida macroura  Mourning Dove  Paul Driver   \n",
       "3  Zenaida macroura  Mourning Dove  Paul Driver   \n",
       "4  Zenaida macroura  Mourning Dove  Paul Driver   \n",
       "\n",
       "                                             license  rating   time  \\\n",
       "0  Creative Commons Attribution-NonCommercial-Sha...     4.0  09:00   \n",
       "1  Creative Commons Attribution-NonCommercial-Sha...     4.0  09:00   \n",
       "2  Creative Commons Attribution-NonCommercial-Sha...     4.0  09:00   \n",
       "3  Creative Commons Attribution-NonCommercial-Sha...     4.0  09:00   \n",
       "4  Creative Commons Attribution-NonCommercial-Sha...     4.0  09:00   \n",
       "\n",
       "                                 url             filename  \\\n",
       "0  https://www.xeno-canto.org/138056  moudov/XC138056.ogg   \n",
       "1  https://www.xeno-canto.org/138056  moudov/XC138056.ogg   \n",
       "2  https://www.xeno-canto.org/138056  moudov/XC138056.ogg   \n",
       "3  https://www.xeno-canto.org/138056  moudov/XC138056.ogg   \n",
       "4  https://www.xeno-canto.org/138056  moudov/XC138056.ogg   \n",
       "\n",
       "   primary_label_index secondary_label_index  fold  \n",
       "0                   33                    []     3  \n",
       "1                   33                    []     0  \n",
       "2                   33                    []     7  \n",
       "3                   33                    []     4  \n",
       "4                   33                    []     0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f4d9a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'calqua/XC661339_sec_420'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df[\"itemid\"].values[6543][38:].replace(\".jpg\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "886e6bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "10 sec mel spectrogram\n",
    "primary label\n",
    "secondary label\n",
    "prediction\n",
    "rating\n",
    "lat & long\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def create_tf_records(fold=0):\n",
    "    df = get_fold(fold)\n",
    "    tfr_filename = (\n",
    "        f\"../data/tfrec/competition/v1/happywhale-2022-train-{fold}-{df.shape[0]}.tfrec\"\n",
    "    )\n",
    "    with tf.io.TFRecordWriter(tfr_filename) as writer:\n",
    "        for i, row in tqdm(df.iterrows()):\n",
    "            itemid = row.itemid\n",
    "            name = itemid[38:].replace(\".jpg\", \"\")\n",
    "            prediction = row.prediction\n",
    "            primary_label_index = row.primary_label_index\n",
    "            secondary_label_index = (\n",
    "                row.secondary_label_index\n",
    "                if len(row.secondary_label_index) > 0\n",
    "                else [-1]\n",
    "            )\n",
    "            # print(secondary_label_index)\n",
    "\n",
    "            rating = row.rating\n",
    "            lat = row.latitude\n",
    "            long = row.longitude\n",
    "            image = tf.io.read_file(itemid)\n",
    "            # audio, sample_rate = tf.audio.decode_wav(audio,\n",
    "            #                                 desired_channels=-1,\n",
    "            #                                 desired_samples=-1)\n",
    "            image_name = str.encode(str(name))\n",
    "            example = serialize_example(\n",
    "                image,\n",
    "                image_name,\n",
    "                primary_label_index,\n",
    "                secondary_label_index,\n",
    "                prediction,\n",
    "                rating,\n",
    "                lat,\n",
    "                long,\n",
    "            )\n",
    "            writer.write(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "37d683a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8939it [00:05, 1613.45it/s]\n",
      "8939it [00:09, 966.11it/s] \n",
      "8939it [00:09, 973.70it/s] \n",
      "8939it [00:09, 971.01it/s] \n",
      "8939it [00:10, 861.50it/s] \n",
      "8939it [00:10, 850.44it/s]\n",
      "8939it [00:10, 868.15it/s] \n",
      "8938it [00:10, 815.58it/s]\n"
     ]
    }
   ],
   "source": [
    "for fold in range(8):\n",
    "    create_tf_records(fold=fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dce92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, random\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf, re, math\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b61b831",
   "metadata": {},
   "source": [
    "## lets visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "791605f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = 152\n",
    "sec_str = 0.5\n",
    "\n",
    "\n",
    "def decode_image(image_data):\n",
    "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
    "    image = (\n",
    "        tf.cast(image, tf.float32) / 255.0\n",
    "    )  # convert image to floats in [0, 1] range\n",
    "    image = tf.image.resize(image, IMAGE_SIZE_)\n",
    "    return image\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "'image': _bytes_feature(image),\n",
    "        'image_name': _bytes_feature(image_name),\n",
    "        'primary_label': _int64_feature(primary_label),\n",
    "        'secondary_label': _int64_feature(secondary_label),\n",
    "        'prediction': _float_feature(prediction),\n",
    "        'rating': _float_feature(rating),\n",
    "        'lat': _float_feature(lat),\n",
    "        'long': _float_feature(long),\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def read_labeled_tfrecord(example):\n",
    "    LABELED_TFREC_FORMAT = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),  # tf.string means bytestring\n",
    "        \"image_name\": tf.io.FixedLenFeature(\n",
    "            [], tf.string\n",
    "        ),  # shape [] means single element\n",
    "        \"primary_label\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"secondary_label\": tf.io.FixedLenSequenceFeature(\n",
    "            [], tf.int64, allow_missing=True\n",
    "        ),\n",
    "        \"prediction\": tf.io.FixedLenFeature([], tf.float32),\n",
    "        \"rating\": tf.io.FixedLenFeature([], tf.float32),\n",
    "        \"lat\": tf.io.FixedLenFeature([], tf.float32),\n",
    "        \"long\": tf.io.FixedLenFeature([], tf.float32),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n",
    "    # example2 = tf.io.parse_tensor(example, LABELED_TFREC_FORMAT)\n",
    "    image = decode_image(example[\"image\"])\n",
    "    label = example[\"image_name\"]\n",
    "    label = example[\"primary_label\"]\n",
    "    secondary_label = example[\"secondary_label\"]\n",
    "    # print('sec',secondary_label)\n",
    "    prediction = example[\"prediction\"]\n",
    "    rating = example[\"rating\"]\n",
    "    lat = example[\"lat\"]\n",
    "    long = example[\"long\"]\n",
    "\n",
    "    label = tf.one_hot(label, classes) * prediction\n",
    "\n",
    "    sec = []\n",
    "    for i in secondary_label:\n",
    "        pass\n",
    "\n",
    "        if i != -1:\n",
    "            # pass\n",
    "\n",
    "            sec.append(tf.one_hot(i, classes) * sec_str)\n",
    "        else:\n",
    "            sec.append([0] * classes)\n",
    "        #'''\n",
    "    if len(sec) > 1:\n",
    "        sec = np.array(sec).sum(axis=1)\n",
    "\n",
    "    # label += sec\n",
    "\n",
    "    return (\n",
    "        image,\n",
    "        label,\n",
    "    )  # prediction, rating, lat, long,# secondary_label # returns a dataset of (image, label) pairs\n",
    "\n",
    "\n",
    "def load_dataset(filenames, labeled=True, ordered=False):\n",
    "    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n",
    "    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n",
    "\n",
    "    ignore_order = tf.data.Options()\n",
    "    if not ordered:\n",
    "        ignore_order.experimental_deterministic = False  # disable order, increase speed\n",
    "\n",
    "    dataset = tf.data.TFRecordDataset(\n",
    "        filenames, num_parallel_reads=AUTO\n",
    "    )  # automatically interleaves reads from multiple files\n",
    "    dataset = dataset.with_options(\n",
    "        ignore_order\n",
    "    )  # uses data as soon as it streams in, rather than in its original order\n",
    "    dataset = dataset.map(read_labeled_tfrecord)\n",
    "    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def get_training_dataset():\n",
    "    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n",
    "    dataset = dataset.repeat()  # the training dataset must repeat for several epochs\n",
    "    dataset = dataset.shuffle(2048)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(\n",
    "        AUTO\n",
    "    )  # prefetch next batch while training (autotune prefetch buffer size)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def count_data_items(filenames):\n",
    "    # the number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n",
    "    n = [\n",
    "        int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1))\n",
    "        for filename in filenames\n",
    "    ]\n",
    "    return np.sum(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "597cbddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy and matplotlib defaults\n",
    "np.set_printoptions(threshold=15, linewidth=80)\n",
    "CLASSES = [0, 1]\n",
    "\n",
    "\n",
    "def batch_to_numpy_images_and_labels(data):\n",
    "    images, labels = data\n",
    "    numpy_images = images.numpy()\n",
    "    numpy_labels = labels.numpy()\n",
    "    # if numpy_labels.dtype == object: # binary string in this case, these are image ID strings\n",
    "    #    numpy_labels = [None for _ in enumerate(numpy_images)]\n",
    "    # If no labels, only image IDs, return None for labels (this is the case for test data)\n",
    "    return numpy_images, numpy_labels\n",
    "\n",
    "\n",
    "def display_single_sample(image, label, subplot, red=False, titlesize=16):\n",
    "    plt.subplot(*subplot)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(image)\n",
    "    title = str(label)\n",
    "    if len(title) > 0:\n",
    "        plt.title(\n",
    "            title,\n",
    "            fontsize=int(titlesize) if not red else int(titlesize / 1.2),\n",
    "            color=\"red\" if red else \"black\",\n",
    "            fontdict={\"verticalalignment\": \"center\"},\n",
    "            pad=int(titlesize / 1.5),\n",
    "        )\n",
    "    return (subplot[0], subplot[1], subplot[2] + 1)\n",
    "\n",
    "\n",
    "def display_batch_of_images(databatch):\n",
    "    \"\"\"\n",
    "    Display single batch Of images\n",
    "    \"\"\"\n",
    "    # data\n",
    "    images, labels = batch_to_numpy_images_and_labels(databatch)\n",
    "    if labels is None:\n",
    "        labels = [None for _ in enumerate(images)]\n",
    "\n",
    "    # auto-squaring: this will drop data that does not fit into square or square-ish rectangle\n",
    "    rows = int(math.sqrt(len(images)))\n",
    "    cols = len(images) // rows\n",
    "\n",
    "    # size and spacing\n",
    "    FIGSIZE = 13.0\n",
    "    SPACING = 0.1\n",
    "    subplot = (rows, cols, 1)\n",
    "    if rows < cols:\n",
    "        plt.figure(figsize=(FIGSIZE, FIGSIZE / cols * rows))\n",
    "    else:\n",
    "        plt.figure(figsize=(FIGSIZE / rows * cols, FIGSIZE))\n",
    "\n",
    "    # display\n",
    "    for i, (image, label) in enumerate(\n",
    "        zip(images[: rows * cols], labels[: rows * cols])\n",
    "    ):\n",
    "        correct = True\n",
    "        dynamic_titlesize = (\n",
    "            FIGSIZE * SPACING / max(rows, cols) * 40 + 3\n",
    "        )  # magic formula tested to work from 1x1 to 10x10 images\n",
    "        subplot = display_single_sample(\n",
    "            image, label, subplot, not correct, titlesize=dynamic_titlesize\n",
    "        )\n",
    "\n",
    "    # layout\n",
    "    plt.tight_layout()\n",
    "    if label is None and predictions is None:\n",
    "        plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    else:\n",
    "        plt.subplots_adjust(wspace=SPACING, hspace=SPACING)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "11926d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 256\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "cb5d7189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "ename": "StagingError",
     "evalue": "in user code:\n\n    /tmp/ipykernel_730/348580236.py:59 read_labeled_tfrecord  *\n        sec = np.array(sec).sum(axis=1)\n    /usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:47 _sum  **\n        return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n\n    AxisError: axis 1 is out of bounds for array of dimension 1\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStagingError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_730/3946706787.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mTRAINING_FILENAMES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'../data/tfrec/competition/v1/happywhale-2022-train-*.tfrec'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAINING_FILENAMES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAINING_FILENAMES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabeled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_730/348580236.py\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(filenames, labeled, ordered)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFRecordDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_parallel_reads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAUTO\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# automatically interleaves reads from multiple files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_order\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# uses data as soon as it streams in, rather than in its original order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_labeled_tfrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0;31m# returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n\u001b[1;32m   1859\u001b[0m         warnings.warn(\"The `deterministic` argument has no effect unless the \"\n\u001b[1;32m   1860\u001b[0m                       \"`num_parallel_calls` argument is specified.\")\n\u001b[0;32m-> 1861\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1862\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m       return ParallelMapDataset(\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   4979\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_inter_op_parallelism\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_inter_op_parallelism\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4980\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preserve_cardinality\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4981\u001b[0;31m     self._map_func = StructuredFunctionWrapper(\n\u001b[0m\u001b[1;32m   4982\u001b[0m         \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4983\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   4216\u001b[0m         \u001b[0mfn_factory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace_tf_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefun_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4218\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4219\u001b[0m     \u001b[0;31m# There is no graph to add in eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4220\u001b[0m     \u001b[0madd_to_graph\u001b[0m \u001b[0;34m&=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3148\u001b[0m          \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorSpec\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3149\u001b[0m     \"\"\"\n\u001b[0;32m-> 3150\u001b[0;31m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0m\u001b[1;32m   3151\u001b[0m         *args, **kwargs)\n\u001b[1;32m   3152\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3114\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3115\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3116\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3117\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3118\u001b[0m       captured = object_identity.ObjectIdentitySet(\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3463\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3296\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3297\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3298\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3299\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3300\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   4193\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   4194\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4195\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4196\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4197\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   4123\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_should_unpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4124\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4125\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4126\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_should_pack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4127\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    693\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    696\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStagingError\u001b[0m: in user code:\n\n    /tmp/ipykernel_730/348580236.py:59 read_labeled_tfrecord  *\n        sec = np.array(sec).sum(axis=1)\n    /usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:47 _sum  **\n        return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n\n    AxisError: axis 1 is out of bounds for array of dimension 1\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SIZE_ = [IMAGE_SIZE, IMAGE_SIZE]\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "TRAINING_FILENAMES = tf.io.gfile.glob(\n",
    "    f\"../data/tfrec/competition/v1/happywhale-2022-train-*.tfrec\"\n",
    ")\n",
    "print(len(TRAINING_FILENAMES))\n",
    "dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n",
    "dataset = dataset.repeat()\n",
    "dataset = dataset.shuffle(2048)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(\n",
    "    AUTO\n",
    ")  # This dataset can directly be passed to keras.fit method\n",
    "print(count_data_items(TRAINING_FILENAMES))\n",
    "\n",
    "# Displaying single batch of TFRecord\n",
    "train_batch = iter(dataset)\n",
    "display_batch_of_images(next(train_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "5f94c314",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = next(train_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ceb63855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32,), dtype=int64, numpy=array([-1, -1, -1, ..., -1, 23, -1])>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c95bf94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0] * 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
